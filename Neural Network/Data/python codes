import pandas as pd
import numpy as np
import re
import matplotlib
matplotlib.rcParams['text.usetex'] = True
from matplotlib import rc
rc("text", usetex=False)
from matplotlib import pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from scipy.stats import lognorm
from statsmodels.distributions.empirical_distribution import ECDF
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers.experimental import preprocessing
from tensorflow.keras.initializers import he_normal

#landslide data
land = pd.read_csv("land.csv", sep=r'\s*,\s*', header=0,index_col=False, engine='python')
land = pd.DataFrame(land)
print(land.columns.to_list())
death = land['deaths_people'].sum()
injure = land['injured_people'].sum()
destroy = land['houses_destroyed'].sum()
damage = land['houses_damaged'].sum()
affect = land['affected_people'].sum()
crop = land['damages_in_crops'].sum()
cattles = land['lost_cattle'].sum()

#data visualizations for landslide data- barplot and pie chart
deaths, injured, destroyed, damaged, affected, crops, cattle =\
    (land['deaths_people'], land['injured_people'], land['houses_destroyed'], land['houses_damaged'],
     land['affected_people'], land['damages_in_crops'], land['lost_cattle'])
variables = ["deaths\n(people)", "injured\n(people)", "destroyed\n(houses)", "damaged\n(houses)", "affected\n(people)",
             "lost\n(crops)", "lost\n(cattle)"]
frequency = [death, injure, destroy, damage, affect, crop, cattles]

plt.pie(frequency, autopct='%1.2f%%', textprops={'fontsize': 10}, labels=variables)
plt.title("Socio Economic Impacts", fontsize=12)
plt.show()

#bar plot
def addlabels(x, y):
    for i in range(len(x)):
        plt.text(i, y[i], y[i])
if __name__ == '__main__':
    x, y = variables, frequency
    plt.bar(x, y)
    addlabels(x, y)
    plt.title("Socio-Economic Impacts due to Landslide")
    plt.xlabel("Variables", fontsize=12)
    plt.xticks(variables, fontsize= 8)
    plt.ylabel("Frequency", fontsize=12)
    plt.show()

#pie chart
county = land['county']
land.groupby('county').size().plot(kind='pie', autopct='%1.2f%%', textprops={'fontsize': 8})
plt.title("Affected counties")
plt.ylabel('')
plt.show()

#earthquake data
quakes = pd.read_csv("earthquake.csv", sep=r'\s*,\s*', header=0, index_col=False, engine='python').fillna(0)
quakes = pd.DataFrame(quakes)
#print(quakes.columns.tolist())# knowing columns' names
quakes['Date'] = pd.to_datetime(quakes['Date'])
quakes['year'] = quakes['Date'].dt.year
quakes['t'] = quakes.age
epicenter = quakes.epicenter.drop_duplicates()
count1 = quakes['epicenter'].value_counts()

#data visualization
#bar plot of years vs earthquake frequency
quakesperyear = pd.crosstab(index=quakes['year'], columns="count")
quakesperyear.plot(kind='barh',figsize=(10,5))
plt.xlabel("No of Earthquakes")
plt.ylabel("year")
plt.legend()
plt.title("Frequency of Earthquakes per Year")
plt.grid(False)
plt.show()

quakesperepicenter = pd.crosstab(index=quakes['epicenter'], columns="count")
quakesperepicenter.plot(kind='barh', figsize=(10,5), color='black')
plt.xlabel("No of Earthquakes")
plt.ylabel("Epicenter")
plt.legend()
plt.title("Frequency of Earthquakes per Epicenter")
plt.grid(False)
plt.show()

quakes.hist(column="magnitude", figsize=(10,5), color='black', range=(1,7))
plt.xlabel('Frequency of earthquake')
plt.ylabel('Magnitude')
plt.title('Histogram for Magnitude')
plt.grid(False)
plt.show()

quakes.boxplot(column="magnitude")
plt.title('Boxplot of Magnitude')
plt.grid(False)
plt.show()

plt.plot(quakes['magnitude'], color='black', marker='o')
plt.title('Distribution of Magnitude', fontsize=14)
plt.xlabel('Instances')
plt.ylabel('Earthquake Magnitude', fontsize=12)
plt.grid(False)
plt.show()


#checking for count of missing values
quakes.loc[quakes["depth"] == 0.0, "depth"] = np.NAN
print(quakes.isnull().sum()[0:7])
#Regression imputation
X = quakes.iloc[:, 1].values.reshape(-1, 1)  # values converts it into a numpy array
Y = quakes.iloc[:, 2].values.reshape(-1, 1)  # -1 means that calculate the dimension of rows, but have 1 column
linear_regressor = LinearRegression()  # create object for the class
linear_regressor.fit(X, Y)  # perform linear regression
Y_pred = linear_regressor.predict(X)  # make predictions
Y_pred = Y_pred.tolist()
print(Y_pred)

#descriptive statistics
print(round(quakes.describe().transpose(), 4))
skewness = quakes.skew(axis=0, skipna=True)#skewness
kurtosis = quakes.kurt(axis=0, skipna=True)#Kurtosis

#Estimating lognormal distribution
t = np.array(quakes['age'])
y = ECDF(t)
#pars1 = lognorm.fit(t)
pars2 = lognorm.fit(t, floc=0)
sigma, loc, scale = lognorm.fit(t, floc=0)
print(round(np.log(lognorm.pdf(t, sigma)).sum(), 4))
print(round(sigma, 4))

#data pre-processing-data normalization i.e x has range [0,1]
quakes = quakes.drop(columns=["epicenter", "Date", "depth", "age", "year"], axis=1)
quakes = quakes[['magnitude', 't', 'latitude', 'longitude']]#rearranging columns
col_names = list(quakes.columns)
#splitting data for training and testing
X = quakes.drop('magnitude', axis=1)
y = quakes['magnitude']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
#data normalization
normalizer = preprocessing.Normalization(axis=-1)
normalizer.adapt(np.array(X, y))

#ANN plus He initialization
#defining the keras model
def build_and_compile_model(normalizer):
  model = keras.models.Sequential([
      normalizer,
      layers.Dense(5, activation='relu', kernel_initializer='he_normal', bias_initializer='he_normal'),
      layers.Dense(3, activation='relu', kernel_initializer='he_normal', bias_initializer='he_normal'),
      layers.Dense(1, activation='linear')
  ])
  model.compile(loss='mse', optimizer='sgd')
  return model
quakes_model = build_and_compile_model(normalizer)
history = quakes_model.fit(X_train, y_train, validation_split=0.2, epochs=200, batch_size=32, shuffle=True, verbose=1)

#predictions
yhat = quakes_model.predict(X_test).flatten()
r2 = r2_score(y_test, yhat)
mae = mean_absolute_error(y_test, yhat)#mean absolute error
mse = mean_squared_error(y_test, yhat)#mean square error
rmse = np.sqrt(mse)#root mean square error for model assessment
print('MAE: %.3f' % mae)
print('RMSE: %.3f' % rmse)
print('R squared: %.3f' %r2)

def plot_loss(history):
  plt.plot(history.history['loss'], label='train')
  plt.plot(history.history['val_loss'], label='test')
  plt.title('Loss Curve Plot')
  #plt.ylim([0, 10])
  plt.xlabel('Epoch')
  plt.ylabel('MSE')
  plt.legend()
  plt.grid(False)
  plt.show()
plot_loss(history)#loss curve plot for model diagnostics

### Conversion to Basic Formula

# temp list as a container for each layer formulas
formula_list = []
# counter of hidden layers
f_n = 1
#
for i in range(len(quakes_model.layers)):
    # get ith Keras layer's weights and biases
    layer = quakes_model.layers[i]
    W = layer.get_weights()

    # empty text string to which concatenate current layer formula parts
    formula = ''
    # set script for input layer
    if i == 0:
        for i in range(W[0].shape[0]):
            cur_weight = np.sum(W[0][i])
            cur_bias = np.sum(W[1][i])
            # build formula for this layer
            formula += '*' + str(np.round(cur_weight, 2)) + '*' + 'x+' + '*' + str(np.round(cur_bias, 2)) + '*' + '/'
        # append this layer formula to temp list
        formula_list.append(formula)

    # set script for hidden layers
    elif i < len(quakes_model.layers)-1:
        # start loop for next layer each neuron
        for c in range(W[0].shape[1]):
            cur_bias = np.sum(W[1][c])
            for i in range(W[0].shape[0]):
                cur_weight = np.sum(W[0][i, c])
                # build formula for this layer using previous layer formula
                formula += '*' + str(np.round(cur_weight, 2)) + '*' + 'f' + str(f_n).join(formula_list[-1].split('/')[i]
                                                                                          ) + 'f' + str(f_n) + '+'
            formula += '*'+str(np.round(cur_bias,2))+'*' + '/'
        # append this layer formula to temp list
        formula_list.append(formula)
        # increase index number for the next hidden layer
        f_n += 1
    # set script for output layer
    else:
        for i in range(W[0].shape[0]):
            cur_weight = np.sum(W[0][i, 0])
            # build formula for this layer using previous layer formula
            formula += '*' + str(np.round(cur_weight, 2)) + '*' + 'f' + str(f_n) + '(' + formula_list[-1].split('/')[
                i] + ')' + 'f' + str(f_n) + '+'
        cur_bias = np.sum(W[1][0])
        formula += '*' + str(np.round(cur_bias, 2)) + '*'
        # append this layer formula to temp list
        formula_list.append(formula)
# get last formula
formula = formula_list[-1]
# make some cleanings
formula = formula.replace('+*-', '-')
formula = formula.replace('+*0.0*', '')
formula = formula.replace('-*0.0*', '')
formula = formula.replace('*', '')

# Create numpy formula
def numpy_activation_function(x):
    return '(np.exp('+x+') - np.exp(-'+x+'))/(np.exp('+x+') + np.exp(-'+x+'))'


formula_numpy = formula
for i in range(1,f_n+1):
    exist = True
    while exist:
        try:
            pattern = 'f'+str(i)+'(.*?)'+'f'+str(i)
            substring = re.search(pattern, formula_numpy).group(1)
            start = re.search(pattern, formula_numpy).start()
            formula_numpy = formula_numpy[:start] + numpy_activation_function(substring) + \
                            formula_numpy[start + 4 + len(substring):]
        except:
            exist = False

formula_numpy = formula_numpy.replace('(np', '*(np')
formula_numpy = formula_numpy.replace('x-', '*x-')
formula_numpy = formula_numpy.replace('x+', '*x+')
formula_numpy = formula_numpy.replace('/*', '/')

print(formula_numpy)

def latex_activation_function(x):
    return '\\frac{e^{'+x+'} - e^{-'+x+'}}{e^{'+x+'} + e^{-'+x+'}}'


formula_latex = formula
for i in range(1, f_n+1):
    exist = True
    while exist:
        try:
            pattern = 'f'+str(i)+'(.*?)'+'f'+str(i)
            substring = re.search(pattern, formula_latex).group(1)
            start = re.search(pattern, formula_latex).start()
            formula_latex = formula_latex[:start] + latex_activation_function(substring) + \
                            formula_latex[start + 4 + len(substring):]
        except:
            exist = False

print(formula_latex)

fig, ax = plt.subplots(figsize=(10, 2), tight_layout=True)
plt.axis('off')
ax.text(0, 0.5, r'$' + formula_latex + '$', fontsize=12, color='b', )
plt.show()
